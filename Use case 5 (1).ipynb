{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88f6d32c-710e-4d98-83ea-9d81f34d2059",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Use Case 5:- Rice Growth Condition Profiling & Prediction Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f468c362-58bd-4c90-8a12-c17b4735bd02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**STEP 1:- Load & Inspect Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4a00c62-c7a6-462f-a95a-37dfbb4cd9af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- N: long (nullable = true)\n |-- P: long (nullable = true)\n |-- K: long (nullable = true)\n |-- temperature: double (nullable = true)\n |-- humidity: double (nullable = true)\n |-- ph: double (nullable = true)\n |-- rainfall: double (nullable = true)\n |-- label: string (nullable = true)\n\n+---+---+---+-----------+-----------+-----------+-----------+-----+\n|  N|  P|  K|temperature|   humidity|         ph|   rainfall|label|\n+---+---+---+-----------+-----------+-----------+-----------+-----+\n| 90| 42| 43|20.87974371|82.00274423|6.502985292|202.9355362| rice|\n| 85| 58| 41|21.77046169|80.31964408|7.038096361|226.6555374| rice|\n| 60| 55| 44|23.00445915| 82.3207629|7.840207144|263.9642476| rice|\n| 74| 35| 40|26.49109635|80.15836264|6.980400905|242.8640342| rice|\n| 78| 42| 42|20.13017482|81.60487287|7.628472891|262.7173405| rice|\n+---+---+---+-----------+-----------+-----------+-----------+-----+\nonly showing top 5 rows\nTotal records: 49\n"
     ]
    }
   ],
   "source": [
    "# Method 1: If you created a table during upload\n",
    "df = spark.table(\"cropprediction\")\n",
    "\n",
    "# OR Method 2: If you uploaded to DBFS and know the path\n",
    "# df = spark.read.csv(\"dbfs:/FileStore/tables/cropprediction.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Print schema\n",
    "df.printSchema()\n",
    "\n",
    "# Show first 5 rows\n",
    "df.show(5)\n",
    "\n",
    "# Check total records\n",
    "print(f\"Total records: {df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f097e43-adb4-47f6-ab07-5c341d73551e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**STEP 2:- Rename Columns for Consistency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bb9f326-7198-4f09-87e8-21d3a2df68f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed columns:\n['NITROGEN', 'PHOSPHORUS', 'POTASSIUM', 'TEMPERATURE', 'HUMIDITY', 'PH', 'RAINFALL', 'CROP_LABEL']\n+--------+----------+---------+-----------+-----------+-----------+-----------+----------+\n|NITROGEN|PHOSPHORUS|POTASSIUM|TEMPERATURE|   HUMIDITY|         PH|   RAINFALL|CROP_LABEL|\n+--------+----------+---------+-----------+-----------+-----------+-----------+----------+\n|      90|        42|       43|20.87974371|82.00274423|6.502985292|202.9355362|      rice|\n|      85|        58|       41|21.77046169|80.31964408|7.038096361|226.6555374|      rice|\n|      60|        55|       44|23.00445915| 82.3207629|7.840207144|263.9642476|      rice|\n|      74|        35|       40|26.49109635|80.15836264|6.980400905|242.8640342|      rice|\n|      78|        42|       42|20.13017482|81.60487287|7.628472891|262.7173405|      rice|\n+--------+----------+---------+-----------+-----------+-----------+-----------+----------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Rename columns to uppercase for consistency\n",
    "df = (df\n",
    "    .withColumnRenamed(\"N\", \"NITROGEN\")\n",
    "    .withColumnRenamed(\"P\", \"PHOSPHORUS\")\n",
    "    .withColumnRenamed(\"K\", \"POTASSIUM\")\n",
    "    .withColumnRenamed(\"temperature\", \"TEMPERATURE\")\n",
    "    .withColumnRenamed(\"humidity\", \"HUMIDITY\")\n",
    "    .withColumnRenamed(\"ph\", \"PH\")\n",
    "    .withColumnRenamed(\"rainfall\", \"RAINFALL\")\n",
    "    .withColumnRenamed(\"label\", \"CROP_LABEL\")\n",
    ")\n",
    "\n",
    "print(\"Renamed columns:\")\n",
    "print(df.columns)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2ba9a0b-dc2f-436d-b2b1-c02b6e11c140",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**STEP 3:- Clean and Filter Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d16bd833-0033-4703-a28a-701cc06e1358",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clean records: 49\n+--------+----------+---------+-----------+-----------+-----------+-----------+----------+\n|NITROGEN|PHOSPHORUS|POTASSIUM|TEMPERATURE|   HUMIDITY|         PH|   RAINFALL|CROP_LABEL|\n+--------+----------+---------+-----------+-----------+-----------+-----------+----------+\n|    90.0|      42.0|     43.0|20.87974371|82.00274423|6.502985292|202.9355362|      rice|\n|    85.0|      58.0|     41.0|21.77046169|80.31964408|7.038096361|226.6555374|      rice|\n|    60.0|      55.0|     44.0|23.00445915| 82.3207629|7.840207144|263.9642476|      rice|\n|    74.0|      35.0|     40.0|26.49109635|80.15836264|6.980400905|242.8640342|      rice|\n|    78.0|      42.0|     42.0|20.13017482|81.60487287|7.628472891|262.7173405|      rice|\n+--------+----------+---------+-----------+-----------+-----------+-----------+----------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# Cast all numeric columns to Double and remove nulls\n",
    "df = (df\n",
    "    .withColumn(\"NITROGEN\", col(\"NITROGEN\").cast(DoubleType()))\n",
    "    .withColumn(\"PHOSPHORUS\", col(\"PHOSPHORUS\").cast(DoubleType()))\n",
    "    .withColumn(\"POTASSIUM\", col(\"POTASSIUM\").cast(DoubleType()))\n",
    "    .withColumn(\"TEMPERATURE\", col(\"TEMPERATURE\").cast(DoubleType()))\n",
    "    .withColumn(\"HUMIDITY\", col(\"HUMIDITY\").cast(DoubleType()))\n",
    "    .withColumn(\"PH\", col(\"PH\").cast(DoubleType()))\n",
    "    .withColumn(\"RAINFALL\", col(\"RAINFALL\").cast(DoubleType()))\n",
    "    .filter(col(\"CROP_LABEL\").isNotNull())\n",
    ")\n",
    "\n",
    "print(f\"Total clean records: {df.count()}\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37d01b6d-3d79-487f-a441-77722f6e2d56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**STEP 4:- Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50a2a99d-485b-49f5-b496-8903ac3feba2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crop distribution:\n+----------+-----+\n|CROP_LABEL|count|\n+----------+-----+\n|      rice|   49|\n+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of crops\n",
    "print(\"Crop distribution:\")\n",
    "df.groupBy(\"CROP_LABEL\").count().orderBy(\"count\", ascending=False).show()\n",
    "\n",
    "# Create a temporary view for SQL analysis\n",
    "df.createOrReplaceTempView(\"crops\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13a0a323-1ca1-47ca-8199-f5f81d53c182",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**STEP 5:- SQL Exploratory Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0398c011-034e-475c-8d90-75ef003e71da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average conditions for each crop:\n+----------+-------------+------------+--------------+-------------+--------+------------+------+------------+\n|CROP_LABEL|total_samples|avg_nitrogen|avg_phosphorus|avg_potassium|avg_temp|avg_humidity|avg_ph|avg_rainfall|\n+----------+-------------+------------+--------------+-------------+--------+------------+------+------------+\n|      rice|           49|       81.31|         47.33|        40.02|   23.59|       82.13|  6.42|      238.94|\n+----------+-------------+------------+--------------+-------------+--------+------------+------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Average conditions per crop\n",
    "print(\"Average conditions for each crop:\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        CROP_LABEL,\n",
    "        COUNT(*) AS total_samples,\n",
    "        ROUND(AVG(NITROGEN), 2) AS avg_nitrogen,\n",
    "        ROUND(AVG(PHOSPHORUS), 2) AS avg_phosphorus,\n",
    "        ROUND(AVG(POTASSIUM), 2) AS avg_potassium,\n",
    "        ROUND(AVG(TEMPERATURE), 2) AS avg_temp,\n",
    "        ROUND(AVG(HUMIDITY), 2) AS avg_humidity,\n",
    "        ROUND(AVG(PH), 2) AS avg_ph,\n",
    "        ROUND(AVG(RAINFALL), 2) AS avg_rainfall\n",
    "    FROM crops\n",
    "    GROUP BY CROP_LABEL\n",
    "    ORDER BY total_samples DESC\n",
    "\"\"\").show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f700cba-8a2a-4792-8197-652b87842834",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**STEP 6:- Prepare ML Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "436b3751-67ac-4f15-a977-524656755d1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature pipeline stages created\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Index the crop labels (convert strings to numeric indices)\n",
    "label_indexer = StringIndexer(inputCol=\"CROP_LABEL\", outputCol=\"label\", handleInvalid=\"keep\")\n",
    "\n",
    "# Assemble all features into a single vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"NITROGEN\", \"PHOSPHORUS\", \"POTASSIUM\", \"TEMPERATURE\", \"HUMIDITY\", \"PH\", \"RAINFALL\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Scale features (important for Naive Bayes)\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "\n",
    "print(\"✅ Feature pipeline stages created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a31cf138-6d37-4c0b-8856-cbe07e2f003e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**STEP 7:- Model Training (Naive Bayes Classification)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8556b16b-3277-4f6a-82a7-1929465cf9b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 36 records\nTest set: 13 records\nTraining model...\n✅ Model trained successfully!\nSample predictions:\n+----------+-----+----------+\n|CROP_LABEL|label|prediction|\n+----------+-----+----------+\n|      rice|  0.0|       0.0|\n|      rice|  0.0|       0.0|\n|      rice|  0.0|       0.0|\n|      rice|  0.0|       0.0|\n|      rice|  0.0|       0.0|\n|      rice|  0.0|       0.0|\n|      rice|  0.0|       0.0|\n|      rice|  0.0|       0.0|\n|      rice|  0.0|       0.0|\n|      rice|  0.0|       0.0|\n+----------+-----+----------+\nonly showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "# Create Naive Bayes classifier\n",
    "nb = NaiveBayes(featuresCol=\"scaledFeatures\", labelCol=\"label\", smoothing=1.0)\n",
    "\n",
    "# Build the pipeline\n",
    "pipeline = Pipeline(stages=[label_indexer, assembler, scaler, nb])\n",
    "\n",
    "# Split data into train and test sets\n",
    "train, test = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"Training set: {train.count()} records\")\n",
    "print(f\"Test set: {test.count()} records\")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training model...\")\n",
    "model = pipeline.fit(train)\n",
    "print(\"✅ Model trained successfully!\")\n",
    "\n",
    "# Make predictions\n",
    "pred = model.transform(test)\n",
    "\n",
    "# Show sample predictions\n",
    "print(\"Sample predictions:\")\n",
    "pred.select(\"CROP_LABEL\", \"label\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ece1cee9-3709-4cc8-a4f2-d2493d8c2b60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**STEP 8:- Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0898fff-1d2e-4f83-83c6-59853c800a7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\uD83C\uDFAF Model Accuracy: 100.0%\n\uD83D\uDCCA F1 Score: 1.0\n\nConfusion Matrix:\n+-----------+----------+-----+\n|actual_crop|prediction|count|\n+-----------+----------+-----+\n|       rice|       0.0|   13|\n+-----------+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Accuracy\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "accuracy = accuracy_evaluator.evaluate(pred)\n",
    "print(f\"\\n\uD83C\uDFAF Model Accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "# F1 Score\n",
    "f1_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"f1\"\n",
    ")\n",
    "f1_score = f1_evaluator.evaluate(pred)\n",
    "print(f\"\uD83D\uDCCA F1 Score: {round(f1_score, 3)}\")\n",
    "\n",
    "# Confusion Matrix view\n",
    "pred.createOrReplaceTempView(\"predictions\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        CROP_LABEL as actual_crop,\n",
    "        prediction,\n",
    "        COUNT(*) as count\n",
    "    FROM predictions\n",
    "    GROUP BY CROP_LABEL, prediction\n",
    "    ORDER BY CROP_LABEL, count DESC\n",
    "\"\"\").show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b98d9fa-037f-4f81-b609-3e548c1d9904",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**STEP 9:- Save Model and Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c953cc9b-db56-49b6-a2a8-c1595cc25ab0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Predictions saved as SQL table: crop_predictions\n\nAccuracy per crop:\n+----------+-----------------+-------------------+------------+\n|CROP_LABEL|total_predictions|correct_predictions|accuracy_pct|\n+----------+-----------------+-------------------+------------+\n|      rice|               13|                 13|       100.0|\n+----------+-----------------+-------------------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Save predictions as a table\n",
    "pred.select(\n",
    "    \"NITROGEN\", \"PHOSPHORUS\", \"POTASSIUM\", \n",
    "    \"TEMPERATURE\", \"HUMIDITY\", \"PH\", \"RAINFALL\",\n",
    "    \"CROP_LABEL\", \"label\", \"prediction\"\n",
    ").write.mode(\"overwrite\").saveAsTable(\"crop_predictions\")\n",
    "\n",
    "print(\"✅ Predictions saved as SQL table: crop_predictions\")\n",
    "\n",
    "# Query accuracy per crop\n",
    "print(\"\\nAccuracy per crop:\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        CROP_LABEL,\n",
    "        COUNT(*) as total_predictions,\n",
    "        SUM(CASE WHEN prediction = label THEN 1 ELSE 0 END) as correct_predictions,\n",
    "        ROUND(AVG(CASE WHEN prediction = label THEN 1 ELSE 0 END) * 100, 2) as accuracy_pct\n",
    "    FROM predictions\n",
    "    GROUP BY CROP_LABEL\n",
    "    ORDER BY accuracy_pct DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f15bdf8-74be-47a3-895d-193f9a25cc90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**STEP 10:- Summary results table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5967dc6-2738-4232-b7c6-f6387ead9efc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>CROP_LABEL</th><th>total_samples</th><th>correct_predictions</th><th>accuracy_pct</th><th>avg_nitrogen</th><th>avg_phosphorus</th><th>avg_potassium</th><th>avg_temp</th><th>avg_humidity</th><th>avg_ph</th><th>avg_rainfall</th></tr></thead><tbody><tr><td>rice</td><td>637</td><td>637</td><td>100.0</td><td>81.31</td><td>47.33</td><td>40.02</td><td>23.59</td><td>82.13</td><td>6.42</td><td>238.94</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "rice",
         637,
         637,
         100.0,
         81.31,
         47.33,
         40.02,
         23.59,
         82.13,
         6.42,
         238.94
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "CROP_LABEL",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "total_samples",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "correct_predictions",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "accuracy_pct",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "avg_nitrogen",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "avg_phosphorus",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "avg_potassium",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "avg_temp",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "avg_humidity",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "avg_ph",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "avg_rainfall",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"IyBDcmVhdGUgY29tcHJlaGVuc2l2ZSByZXN1bHRzIHRhYmxlCmNvbXByZWhlbnNpdmVfcmVzdWx0cyA9IHNwYXJrLnNxbCgiIiIKICAgIFNFTEVDVCAKICAgICAgICBwLkNST1BfTEFCRUwsCiAgICAgICAgQ09VTlQoKikgYXMgdG90YWxfc2FtcGxlcywKICAgICAgICBTVU0oQ0FTRSBXSEVOIHAucHJlZGljdGlvbiA9IHAubGFiZWwgVEhFTiAxIEVMU0UgMCBFTkQpIGFzIGNvcnJlY3RfcHJlZGljdGlvbnMsCiAgICAgICAgUk9VTkQoQVZHKENBU0UgV0hFTiBwLnByZWRpY3Rpb24gPSBwLmxhYmVsIFRIRU4gMSBFTFNFIDAgRU5EKSAqIDEwMCwgMikgYXMgYWNjdXJhY3lfcGN0LAogICAgICAgIFJPVU5EKEFWRyhjLk5JVFJPR0VOKSwgMikgYXMgYXZnX25pdHJvZ2VuLAogICAgICAgIFJPVU5EKEFWRyhjLlBIT1NQSE9SVVMpLCAyKSBhcyBhdmdfcGhvc3Bob3J1cywKICAgICAgICBST1VORChBVkcoYy5QT1RBU1NJVU0pLCAyKSBhcyBhdmdfcG90YXNzaXVtLAogICAgICAgIFJPVU5EKEFWRyhjLlRFTVBFUkFUVVJFKSwgMikgYXMgYXZnX3RlbXAsCiAgICAgICAgUk9VTkQoQVZHKGMuSFVNSURJVFkpLCAyKSBhcyBhdmdfaHVtaWRpdHksCiAgICAgICAgUk9VTkQoQVZHKGMuUEgpLCAyKSBhcyBhdmdfcGgsCiAgICAgICAgUk9VTkQoQVZHKGMuUkFJTkZBTEwpLCAyKSBhcyBhdmdfcmFpbmZhbGwKICAgIEZST00gcHJlZGljdGlvbnMgcAogICAgSk9JTiBjcm9wcyBjIE9OIHAuQ1JPUF9MQUJFTCA9IGMuQ1JPUF9MQUJFTAogICAgR1JPVVAgQlkgcC5DUk9QX0xBQkVMCiAgICBPUkRFUiBCWSBwLkNST1BfTEFCRUwKIiIiKQoKZGlzcGxheShjb21wcmVoZW5zaXZlX3Jlc3VsdHMp\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksViewa0155e8\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksViewa0155e8\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksViewa0155e8\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksViewa0155e8) SELECT `CROP_LABEL`,`avg_temp`,`avg_phosphorus`,`avg_nitrogen`,`avg_potassium`,`avg_humidity`,`avg_ph`,`avg_rainfall` FROM q\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksViewa0155e8\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "CROP_LABEL",
             "id": "column_d6819d2c354"
            },
            "y": [
             {
              "column": "avg_temp",
              "id": "column_d6819d2c376"
             },
             {
              "column": "avg_phosphorus",
              "id": "column_d6819d2c377"
             },
             {
              "column": "avg_nitrogen",
              "id": "column_d6819d2c378"
             },
             {
              "column": "avg_potassium",
              "id": "column_d6819d2c379"
             },
             {
              "column": "avg_humidity",
              "id": "column_d6819d2c380"
             },
             {
              "column": "avg_ph",
              "id": "column_d6819d2c381"
             },
             {
              "column": "avg_rainfall",
              "id": "column_d6819d2c382"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "box",
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "avg_humidity": {
             "type": "box",
             "yAxis": 0
            },
            "avg_nitrogen": {
             "type": "box",
             "yAxis": 0
            },
            "avg_ph": {
             "type": "box",
             "yAxis": 0
            },
            "avg_phosphorus": {
             "type": "box",
             "yAxis": 0
            },
            "avg_potassium": {
             "type": "box",
             "yAxis": 0
            },
            "avg_rainfall": {
             "type": "box",
             "yAxis": 0
            },
            "avg_temp": {
             "type": "box",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "ff8a50cd-7a05-4d4a-9289-40f85f681284",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 110.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "selects": [
          {
           "column": "CROP_LABEL",
           "type": "column"
          },
          {
           "column": "avg_temp",
           "type": "column"
          },
          {
           "column": "avg_phosphorus",
           "type": "column"
          },
          {
           "column": "avg_nitrogen",
           "type": "column"
          },
          {
           "column": "avg_potassium",
           "type": "column"
          },
          {
           "column": "avg_humidity",
           "type": "column"
          },
          {
           "column": "avg_ph",
           "type": "column"
          },
          {
           "column": "avg_rainfall",
           "type": "column"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": [],
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create comprehensive results table\n",
    "comprehensive_results = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        p.CROP_LABEL,\n",
    "        COUNT(*) as total_samples,\n",
    "        SUM(CASE WHEN p.prediction = p.label THEN 1 ELSE 0 END) as correct_predictions,\n",
    "        ROUND(AVG(CASE WHEN p.prediction = p.label THEN 1 ELSE 0 END) * 100, 2) as accuracy_pct,\n",
    "        ROUND(AVG(c.NITROGEN), 2) as avg_nitrogen,\n",
    "        ROUND(AVG(c.PHOSPHORUS), 2) as avg_phosphorus,\n",
    "        ROUND(AVG(c.POTASSIUM), 2) as avg_potassium,\n",
    "        ROUND(AVG(c.TEMPERATURE), 2) as avg_temp,\n",
    "        ROUND(AVG(c.HUMIDITY), 2) as avg_humidity,\n",
    "        ROUND(AVG(c.PH), 2) as avg_ph,\n",
    "        ROUND(AVG(c.RAINFALL), 2) as avg_rainfall\n",
    "    FROM predictions p\n",
    "    JOIN crops c ON p.CROP_LABEL = c.CROP_LABEL\n",
    "    GROUP BY p.CROP_LABEL\n",
    "    ORDER BY p.CROP_LABEL\n",
    "\"\"\")\n",
    "\n",
    "display(comprehensive_results)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Use case 5",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}